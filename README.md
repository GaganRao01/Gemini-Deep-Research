<h1 align="center">üöÄ Gemini Deep Research Platform</h1>

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python 3.9+">
  <img src="https://img.shields.io/badge/Google_Gemini-1.5_Pro-4285F4?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini 1.5 Pro">
  <img src="https://img.shields.io/badge/Google_Search_API-4285F4?style=for-the-badge&logo=google&logoColor=white" alt="Google Search API">
</div>

<div align="center">
  <p><i>An AI-powered research system that generates comprehensive reports using Google's Gemini 1.5 Pro, Google Search, and web scraping.</i></p>
</div>

---

> ‚ö†Ô∏è **Personal Project Disclaimer**  
> This is a personal project where I tried to replicate the deep research capabilities of Gemini. It‚Äôs not perfect and has some rough edges, but building it was an exciting and insightful learning experience. The project is meant for educational and experimental purposes only and is not affiliated with or endorsed by Google. Contributions and feedback are welcome!

---

## üìñ Overview

**Gemini Deep Research** is an automated system designed to perform in-depth research on a given topic. It uses Google Gemini 1.5 Pro to generate relevant search queries, utilizes the Google Custom Search API to find web sources, scrapes content from those sources, and then employs Gemini again to synthesize the gathered information into a structured, well-cited report. The level of detail and length of the report can be adjusted using different depth levels.

---

## üîé Project Files

| File/Folder            | Purpose                                                    |
|------------------------|------------------------------------------------------------|
| **`gemini_research.py`** | The main Python script containing the core logic.        |
| `CODE_DOCUMENTATION.md` | Detailed technical documentation of the codebase.        |
| `README.md`            | This file - Overview and usage instructions.              |
| `.env.example`         | Template for creating your `.env` file with API keys.     |
| `requirements.txt`     | List of necessary Python dependencies.                    |
| `.gitignore`           | Specifies intentionally untracked files for Git.          |
| `research_report_Quantum_computing_applications.md` | Example reports generated by the script (if included).    |

---

## ‚ú® Features

- üß† **Gemini 1.5 Pro Integration**: Leverages Google's powerful LLM for intelligent search query generation and report synthesis.
- üï∏Ô∏è **Automated Web Research**: Uses Google Custom Search API to find relevant online sources.
- ‚úÇÔ∏è **Content Scraping**: Extracts main text content from articles using `newspaper3k` with a `BeautifulSoup` fallback for robustness.
- üìä **Configurable Research Depth**: Choose from 3 levels (Basic, Detailed, Comprehensive) to control report length and detail.
- üéØ **Targeted Search**: Optionally restrict searches to specific websites (`--site`).
- üìÖ **Recency Focus**: Prioritizes recent information through date filtering in search queries and metadata extraction.
- üìö **Structured Reports**: Generates reports with standard sections (Executive Summary, Introduction, Main Content, Challenges, Future Directions, Conclusion, References).
- üîó **Citation Handling**: Includes in-text citations (basic format) and consolidates sources into a final References section.
- üìù **Sectional Synthesis (Depth 2 & 3)**: Breaks down complex topics into sections for more manageable and detailed report generation by the AI.
- üìÑ **Markdown Output**: Saves the final report in a clean Markdown format.
- ‚öôÔ∏è **Customizable Parameters**: Control the number of search queries and results per query.
- ‚ö†Ô∏è **Error Handling**: Includes mechanisms to handle common issues like API errors, scraping failures, and timeouts.

---


## üîÅ LLM Flexibility: Use Local Models Too!

While this project is optimized for **Google Gemini 1.5 Pro**, you can also use **local LLMs** through tools like:

- üß† **[Ollama](https://ollama.com)** ‚Äî Easily run models like Mistral, LLaMA, or Qwen locally.
- üñ•Ô∏è **[LM Studio](https://lmstudio.ai/)** ‚Äî GUI-based local LLM runner with fast inference and API compatibility.

> üí° This allows you to experiment with fully offline generation or reduce API costs by using open-source models.

To integrate a local LLM:
- Swap Gemini API calls in `gemini_research.py` with calls to your local model's API (usually `http://localhost:11434` for Ollama).
- Ensure your local model supports multi-turn chat and has enough context length for large inputs.

Example usage (Ollama):

```bash
ollama run mistral
# or serve via API
ollama serve
```

Then modify the code to send generation prompts to your local endpoint.

---

## ‚öôÔ∏è Command Line Arguments

| Argument           | Alias | Description                                                 | Default          |
|--------------------|-------|-------------------------------------------------------------|------------------|
| `--context`        | `-c`  | The research topic or question (Required).                  | N/A              |
| `--depth`          |  `--depth`    | Research depth (1=Basic, 2=Detailed, 3=Comprehensive).      | `1`              |
| `--queries`        | `-q`  | Number of search queries to generate (Optional).            | Based on `depth` |
| `--results`        | `-r`  | Number of results per query (Optional, max 10 via API).     | Based on `depth` |
| `--site`           | `-s`  | Restrict search to a specific site (e.g., `wikipedia.org`). | `None`           |
| `--verbose`        |  `--verbose`     | Verbosity level (0=minimal, 1=regular, 2=debug - Not implemented yet). | `1`              |

---

## üöÄ Research Depth Levels

| Level | Name          | Description                             | Default Queries | Default Results/Query | Target Min Words* |
|-------|---------------|-----------------------------------------|-----------------|-----------------------|--------------------|
| 1     | Basic         | Key findings, clear overview.           | 3               | 2                     | ~2,500             |
| 2     | Detailed      | Thorough analysis, subtopic exploration.| 5               | 3                     | ~5,000             |
| 3     | Comprehensive | In-depth analysis, diverse perspectives.| 8               | 4                     | ~10,000            |

_*Note: Word counts are targets provided to the AI and approximate. Actual output length may vary._

---

## üõ†Ô∏è Usage

```bash
# Basic Research (Depth 1 - Default)
python gemini_research.py -c "Future of renewable energy"

# Detailed Research (Depth 2)
python gemini_research.py -c "Impact of artificial intelligence on education" --depth 2

# Comprehensive Research (Depth 3) with Site Restriction
python gemini_research.py -c "Quantum computing applications in cryptography" --depth 3 --site "arxiv.org"

# Specify Queries and Results
python gemini_research.py -c "Latest advancements in mRNA vaccine technology" --depth 2 --queries 6 --results 5

# all  available arguments using Alias
python gemini_research.py -c "AI in agriculture" --depth 1 -q 2 -r 2 --verbose 1
```

---

## üîç How It Works (Sequential Process)

1. **Initialization**: Loads API keys from `.env` and parses CLI arguments.
2. **Query Generation**: Sends topic to Gemini to generate specific search queries.
3. **Research Execution**:
   - Searches Google with each query using the Custom Search API.
   - Scrapes articles using `newspaper3k` or `BeautifulSoup`.
4. **Report Synthesis**:
   - Gemini writes the full report based on content and metadata.
   - In-depth reports (depth 2 & 3) use a sectional breakdown.
5. **Formatting & Output**: Markdown formatting with clear sections and final `.md` file export.

---

## üìã Example Report Structure

- **Title**  
- **Publication Date**  
- **Executive Summary**  
- **Introduction**  
- **Main Content Sections**  
- **Challenges and Limitations**  
- **Future Directions**  
- **Conclusion**  
- **References**
  
#### üìÑ Sample Report: [research_report_Quantum_computing_applications.md](research_report_Quantum_computing_applications.md)

## üõ†Ô∏è Known Issues in Report Generation

The current report generation process uses a sectional (chunk-based) approach implemented in the `synthesis_report()` function. While this enables modular generation, it also introduces some limitations:

- Topics may be **repeated** across different sections.
- **References are inconsistently placed**, often scattered throughout the document instead of being consolidated at the end.
- Each section is generated **independently** with its own references, and the existing pattern matching logic for reference extraction doesn't consistently detect all formats.

These issues arise from the independent nature of section-wise generation and limitations in post-processing.


---

## üßë‚Äçüíª Getting Started

### Prerequisites

- Python 3.9+
- Git
- Google Gemini API Key (from AI Studio)
- Google Custom Search API Key + CSE ID

### Installation

```bash
# Clone repo
git clone <repository_url>
cd <repository_directory>

# Create virtual environment
python -m venv venv
# Activate (Windows)
.\venv\Scripts\activate
# Activate (macOS/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Then edit .env and add your keys
```

---

## üèÅ Running the Script

Use the commands in the Usage section. The output report is saved as a `.md` file in the project directory.

---

## üìú License

This project is licensed under the  `MIT License `.

---

## üôè Acknowledgements

- [Google Gemini](https://ai.google.dev/gemini)  
- [Google Custom Search](https://developers.google.com/custom-search)  
- [Newspaper3k](https://github.com/codelucas/newspaper)  
- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)
---
